This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.env.example
.gitignore
backend/.env.example
docker-compose.prod.yml
docker-compose.yml
frontend/.env.example
LICENSE
readme.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
# SENSITIVE DATA - NEVER COMMIT THESE
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
*.env
.env.*
!.env.example

# AWS Credentials and Config
.aws/
aws-credentials.json
terraform.tfvars
*.pem
*.key

# Database
*.db
*.sqlite
*.sqlite3

# =============================================================================
# PYTHON / FASTAPI BACKEND
# =============================================================================

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff (just in case):
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pdm
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# =============================================================================
# NODE.JS / REACT FRONTEND
# =============================================================================

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# parcel-bundler cache (https://parceljs.org/)
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# Vite build output
dist
dist-ssr
*.local

# Rollup.js default build output
dist/

# Webpack
.webpack/

# SvelteKit build / generate output
.svelte-kit

# =============================================================================
# DOCKER
# =============================================================================
# Override docker-compose files
docker-compose.override.yml

# Docker volumes
.docker/

# =============================================================================
# TERRAFORM / AWS
# =============================================================================
# Local .terraform directories
**/.terraform/*

# .tfstate files
*.tfstate
*.tfstate.*

# Crash log files
crash.log
crash.*.log

# Exclude all .tfvars files, which are likely to contain sensitive data
*.tfvars
*.tfvars.json

# Ignore override files as they are usually used to override resources locally
override.tf
override.tf.json
*_override.tf
*_override.tf.json

# Include override files you do wish to add to version control using negated pattern
# !example_override.tf

# Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan
*tfplan*

# Ignore CLI configuration files
.terraformrc
terraform.rc

# =============================================================================
# SELENIUM / WEB SCRAPING
# =============================================================================
# Chrome driver and browser downloads
chromedriver*
geckodriver*
selenium-server-standalone-*
drivers/
browser_cache/
screenshots/
downloads/

# =============================================================================
# IDE AND EDITOR FILES
# =============================================================================
# Visual Studio Code
.vscode/
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
!.vscode/*.code-snippets

# Local History for Visual Studio Code
.history/

# Built Visual Studio Code Extensions
*.vsix

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be added to the global gitignore or merged into this file.
.idea/
*.iws
*.iml
*.ipr

# Vim
*~
*.swp
*.swo
*tmp

# Emacs
*~
\#*\#
/.emacs.desktop
/.emacs.desktop.lock
*.elc
auto-save-list
tramp
.\#*

# =============================================================================
# OPERATING SYSTEM FILES
# =============================================================================

# macOS
.DS_Store
.AppleDouble
.LSOverride
Icon
._*
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# Windows
Thumbs.db
Thumbs.db:encryptable
ehthumbs.db
ehthumbs_vista.db
*.tmp
*.temp
Desktop.ini
$RECYCLE.BIN/
*.cab
*.msi
*.msix
*.msm
*.msp
*.lnk

# Linux
*~
.fuse_hidden*
.directory
.Trash-*
.nfs*

# =============================================================================
# PROJECT SPECIFIC
# =============================================================================
# Scraped data output
scraped_data/
export_data/
temp_data/
data_dumps/

# User uploaded files
uploads/
user_files/

# Generated fake profiles
generated_profiles/
fake_data_cache/

# Campaign execution logs
campaign_logs/
execution_results/

# Backup files
*.bak
*.backup
*.old

# Local development overrides
local_settings.py
dev_config.json

project-management/
</file>

<file path="backend/.env.example">
# =============================================================================
# MIASMA BACKEND ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit the actual .env file to version control

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
APP_NAME=Miasma
APP_VERSION=0.1.0
DEBUG=true
ENVIRONMENT=development

# API Configuration
API_V1_STR=/api/v1
SECRET_KEY=your-super-secret-key-change-this-in-production-minimum-32-characters
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# Server Configuration
HOST=0.0.0.0
PORT=8000
RELOAD=true

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# PostgreSQL Database
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_USER=miasma_user
POSTGRES_PASSWORD=your-database-password
POSTGRES_DB=miasma_db

# Database URL (automatically constructed from above, or override)
DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_SERVER}:${POSTGRES_PORT}/${POSTGRES_DB}

# Database Pool Settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your-redis-password
REDIS_DB=0
REDIS_URL=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}

# Cache Settings
CACHE_TTL_SECONDS=300
SESSION_TTL_SECONDS=86400

# =============================================================================
# SECURITY SETTINGS
# =============================================================================
# CORS Settings
BACKEND_CORS_ORIGINS=["http://localhost:3000","http://localhost:5173","http://127.0.0.1:3000","http://127.0.0.1:5173"]

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000

# Password Requirements
MIN_PASSWORD_LENGTH=8
REQUIRE_UPPERCASE=true
REQUIRE_LOWERCASE=true
REQUIRE_NUMBERS=true
REQUIRE_SPECIAL_CHARS=true

# =============================================================================
# WEB SCRAPING CONFIGURATION
# =============================================================================
# Selenium Settings
SELENIUM_HUB_URL=http://selenium:4444/wd/hub
CHROME_OPTIONS=--headless,--no-sandbox,--disable-dev-shm-usage,--disable-gpu
SELENIUM_TIMEOUT=30
PAGE_LOAD_TIMEOUT=30

# Scraping Behavior
REQUEST_DELAY_MIN=1
REQUEST_DELAY_MAX=3
MAX_RETRIES=3
CONCURRENT_SCRAPERS=2

# User Agent Settings
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36

# =============================================================================
# DATA BROKER SITES CONFIGURATION
# =============================================================================
# Enable/Disable specific scrapers
ENABLE_WHITEPAGES=true
ENABLE_SPOKEO=true
ENABLE_TRUEPEOPLESEARCH=true
ENABLE_BEENVERIFIED=true
ENABLE_INTELIUS=false

# Scraper-specific settings (add API keys if available)
WHITEPAGES_API_KEY=your-whitepages-api-key-if-available
SPOKEO_API_KEY=your-spokeo-api-key-if-available

# =============================================================================
# DATA GENERATION SETTINGS
# =============================================================================
# Fake Data Generation
FAKER_LOCALE=en_US
GENERATE_REALISTIC_ADDRESSES=true
USE_REAL_ZIPCODES=true
AVOID_OBVIOUS_FAKE_NAMES=true

# Campaign Settings
MAX_CAMPAIGNS_PER_USER=10
MAX_SUBMISSIONS_PER_CAMPAIGN=100
CAMPAIGN_EXECUTION_DELAY_HOURS=24

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=logs/miasma.log
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5

# Enable specific loggers
LOG_DATABASE=false
LOG_SCRAPERS=true
LOG_CAMPAIGNS=true
LOG_SECURITY=true

# =============================================================================
# AWS CONFIGURATION (for production)
# =============================================================================
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key

# S3 Configuration (for file storage)
S3_BUCKET=miasma-data-bucket
S3_REGION=us-east-1

# SES Configuration (for email notifications)
SES_SENDER_EMAIL=noreply@yourdomain.com
SES_REGION=us-east-1

# =============================================================================
# MONITORING & ANALYTICS
# =============================================================================
# Enable monitoring
ENABLE_METRICS=true
METRICS_PORT=8001

# External monitoring services
SENTRY_DSN=your-sentry-dsn-for-error-tracking

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Only used in development
DEV_SEED_DATA=true
DEV_MOCK_SCRAPERS=false
DEV_BYPASS_RATE_LIMITS=true

# Testing
TEST_DATABASE_URL=postgresql+asyncpg://test_user:test_pass@localhost:5432/miasma_test
PYTEST_TIMEOUT=30
</file>

<file path="docker-compose.prod.yml">
version: '3.8'

# Production Docker Compose Configuration
# Usage: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up

services:
  # =============================================================================
  # APPLICATION SERVICES (PRODUCTION OVERRIDES)
  # =============================================================================

  backend:
    build:
      target: production
    restart: always
    environment:
      # Production settings
      DEBUG: false
      ENVIRONMENT: production
      DEV_MODE: false
      HOT_RELOAD: false
      
      # Security
      BACKEND_CORS_ORIGINS: '["https://yourdomain.com","https://www.yourdomain.com"]'
      
      # Logging
      LOG_LEVEL: INFO
      
      # Performance
      DB_POOL_SIZE: 20
      DB_MAX_OVERFLOW: 40
      
      # Rate limiting
      RATE_LIMIT_PER_MINUTE: 30
      RATE_LIMIT_PER_HOUR: 500
    volumes:
      # Remove development volume mounts
      - ./logs:/app/logs
      - ./data/scraped:/app/data/scraped
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: '2.0'
        reservations:
          memory: 1g
          cpus: '1.0'
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      rollback_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  frontend:
    build:
      target: production
    restart: always
    environment:
      # Production API URLs
      VITE_API_BASE_URL: https://api.yourdomain.com
      VITE_API_URL: https://api.yourdomain.com/api/v1
      VITE_WS_URL: wss://api.yourdomain.com/ws
      
      # Production settings
      VITE_NODE_ENV: production
      VITE_ENABLE_DEBUG_MODE: false
      VITE_USE_MOCK_DATA: false
      VITE_SHOW_DEV_TOOLS: false
    volumes:
      # Remove development volume mounts
      []
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: '1.0'
        reservations:
          memory: 512m
          cpus: '0.5'
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  # =============================================================================
  # DATABASE SERVICES (PRODUCTION OVERRIDES)
  # =============================================================================

  postgres:
    restart: always
    environment:
      # Production tuning
      POSTGRES_SHARED_PRELOAD_LIBRARIES: pg_stat_statements
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
      POSTGRES_WORK_MEM: 4MB
      POSTGRES_MAINTENANCE_WORK_MEM: 64MB
    volumes:
      - postgres_data:/var/lib/postgresql/data/pgdata
      - ./backups:/backups
      - ./scripts/postgres-prod.conf:/etc/postgresql/postgresql.conf:ro
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: '2.0'
        reservations:
          memory: 1g
          cpus: '1.0'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  redis:
    restart: always
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: '1.0'
        reservations:
          memory: 256m
          cpus: '0.5'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  # =============================================================================
  # SELENIUM (PRODUCTION SCALING)
  # =============================================================================

  selenium:
    restart: always
    environment:
      SE_NODE_MAX_SESSIONS: 5
      SE_NODE_MAX_INSTANCES: 5
      # Remove VNC in production
      SE_START_XVFB: false
    ports:
      # Remove VNC port in production
      - "${SELENIUM_PORT:-4444}:4444"
    deploy:
      resources:
        limits:
          memory: 4g
          cpus: '3.0'
        reservations:
          memory: 2g
          cpus: '2.0'
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3

  # =============================================================================
  # PRODUCTION SERVICES
  # =============================================================================

  nginx:
    image: nginx:alpine
    container_name: miasma-nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/sites-enabled:/etc/nginx/sites-enabled:ro
      - ./ssl:/etc/ssl/certs:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - frontend
      - backend
    networks:
      - miasma-network
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: '0.5'

  # Backup service
  backup:
    image: postgres:15-alpine
    container_name: miasma-backup
    restart: "no"
    environment:
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    depends_on:
      - postgres
    networks:
      - miasma-network
    command: ["/bin/sh", "/backup.sh"]
    profiles:
      - backup

  # Log aggregation
  fluentd:
    image: fluentd:latest
    container_name: miasma-fluentd
    restart: always
    volumes:
      - ./logs:/fluentd/log
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
    networks:
      - miasma-network
    profiles:
      - monitoring

# =============================================================================
# PRODUCTION VOLUMES
# =============================================================================

volumes:
  postgres_data:
    external: true
    name: miasma-postgres-data
  
  redis_data:
    external: true  
    name: miasma-redis-data
</file>

<file path="docker-compose.yml">
version: '3.8'

services:
  # =============================================================================
  # DATABASE SERVICES
  # =============================================================================
  
  postgres:
    image: postgres:${POSTGRES_VERSION:-15-alpine}
    container_name: miasma-postgres
    restart: unless-stopped
    environment:
      POSTGRES_SERVER: ${POSTGRES_SERVER:-postgres}
      POSTGRES_USER: ${POSTGRES_USER:-miasma_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-change-this-secure-password}
      POSTGRES_DB: ${POSTGRES_DB:-miasma_db}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data/pgdata
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    networks:
      - miasma-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-miasma_user} -d ${POSTGRES_DB:-miasma_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: ${DATABASE_MEMORY:-512m}
          cpus: '${DATABASE_CPUS:-1.0}'

  redis:
    image: redis:${REDIS_VERSION:-7-alpine}
    container_name: miasma-redis
    restart: unless-stopped
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-change-this-redis-password}
      --appendonly yes
      --appendfsync everysec
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    ports:
      - "${CACHE_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    networks:
      - miasma-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: ${REDIS_MEMORY:-256m}
          cpus: '${REDIS_CPUS:-0.5}'

  # =============================================================================
  # APPLICATION SERVICES
  # =============================================================================

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: development
    container_name: miasma-backend
    restart: unless-stopped
    environment:
      # Application
      APP_NAME: ${APP_NAME:-Miasma}
      DEBUG: ${DEBUG:-true}
      ENVIRONMENT: ${ENVIRONMENT:-development}
      
      # Database
      POSTGRES_SERVER: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-miasma_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-change-this-secure-password}
      POSTGRES_DB: ${POSTGRES_DB:-miasma_db}
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-miasma_user}:${POSTGRES_PASSWORD:-change-this-secure-password}@postgres:5432/${POSTGRES_DB:-miasma_db}
      
      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-change-this-redis-password}
      REDIS_URL: redis://:${REDIS_PASSWORD:-change-this-redis-password}@redis:6379/0
      
      # Security
      SECRET_KEY: ${SECRET_KEY:-your-super-secret-jwt-key-minimum-32-characters-change-in-production}
      ALGORITHM: ${ALGORITHM:-HS256}
      
      # CORS
      BACKEND_CORS_ORIGINS: '["http://localhost:3000","http://localhost:5173","http://127.0.0.1:3000","http://127.0.0.1:5173"]'
      
      # Selenium
      SELENIUM_HUB_URL: http://selenium:4444/wd/hub
      
      # Development
      DEV_MODE: ${DEV_MODE:-true}
      HOT_RELOAD: ${HOT_RELOAD:-true}
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    volumes:
      - ./backend:/app
      - ./logs:/app/logs
      - ./data/scraped:/app/data/scraped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - miasma-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: ${BACKEND_MEMORY:-1g}
          cpus: '${BACKEND_CPUS:-1.0}'

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    container_name: miasma-frontend
    restart: unless-stopped
    environment:
      # Vite development server
      VITE_DEV_SERVER_HOST: 0.0.0.0
      VITE_DEV_SERVER_PORT: 3000
      
      # API Configuration
      VITE_API_BASE_URL: http://localhost:${BACKEND_PORT:-8000}
      VITE_API_URL: http://localhost:${BACKEND_PORT:-8000}/api/v1
      VITE_WS_URL: ws://localhost:${BACKEND_PORT:-8000}/ws
      
      # Development
      VITE_NODE_ENV: ${ENVIRONMENT:-development}
      VITE_ENABLE_DEBUG_MODE: ${DEBUG:-true}
      VITE_HOT_RELOAD: ${HOT_RELOAD:-true}
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules  # Anonymous volume for node_modules
    depends_on:
      - backend
    networks:
      - miasma-network
    stdin_open: true
    tty: true
    deploy:
      resources:
        limits:
          memory: ${FRONTEND_MEMORY:-512m}
          cpus: '${FRONTEND_CPUS:-0.5}'

  # =============================================================================
  # WEB SCRAPING SERVICES
  # =============================================================================

  selenium:
    image: seleniarm/standalone-chromium:${SELENIUM_VERSION:-4.15.0}
    container_name: miasma-selenium
    restart: unless-stopped
    environment:
      # Selenium Hub Configuration
      SE_NODE_MAX_SESSIONS: ${SELENIUM_NODE_MAX_SESSIONS:-2}
      SE_NODE_MAX_INSTANCES: ${SELENIUM_NODE_MAX_INSTANCES:-2}
      SE_NODE_OVERRIDE_MAX_SESSIONS: true
      
      # Chrome Configuration
      SE_CHROME_OPTS: "--headless --no-sandbox --disable-dev-shm-usage --disable-gpu --window-size=1920,1080"
      
      # VNC (for debugging - remove in production)
      SE_VNC_NO_PASSWORD: 1
      SE_START_XVFB: true
    ports:
      - "${SELENIUM_PORT:-4444}:4444"
      - "7900:7900"  # VNC port for debugging
    volumes:
      - /dev/shm:/dev/shm
      - ./data/screenshots:/home/seluser/screenshots
      - ./data/downloads:/home/seluser/downloads
    networks:
      - miasma-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4444/wd/hub/status"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: ${SELENIUM_MEMORY:-2g}
          cpus: '${SELENIUM_CPUS:-2.0}'

  # =============================================================================
  # DEVELOPMENT TOOLS
  # =============================================================================

  adminer:
    image: adminer:latest
    container_name: miasma-adminer
    restart: unless-stopped
    environment:
      ADMINER_DEFAULT_SERVER: postgres
      ADMINER_DESIGN: nette
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    networks:
      - miasma-network
    profiles:
      - dev-tools

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: miasma-redis-commander
    restart: unless-stopped
    environment:
      REDIS_HOSTS: local:redis:6379:0:${REDIS_PASSWORD:-change-this-redis-password}
      HTTP_USER: admin
      HTTP_PASSWORD: admin
    ports:
      - "8081:8081"
    depends_on:
      - redis
    networks:
      - miasma-network
    profiles:
      - dev-tools

# =============================================================================
# VOLUMES
# =============================================================================

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DB_DATA_PATH:-./data/postgres}
  
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${REDIS_DATA_PATH:-./data/redis}

# =============================================================================
# NETWORKS
# =============================================================================

networks:
  miasma-network:
    driver: bridge
    name: miasma-network
</file>

<file path=".env.example">
# =============================================================================
# MIASMA - DOCKER COMPOSE ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your actual values
# This file is used by docker-compose.yml for container configuration

# =============================================================================
# GLOBAL SETTINGS
# =============================================================================
COMPOSE_PROJECT_NAME=miasma
ENVIRONMENT=development

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
POSTGRES_SERVER=postgres
POSTGRES_PORT=5432
POSTGRES_USER=miasma_user
POSTGRES_PASSWORD=change-this-secure-password
POSTGRES_DB=miasma_db

# PostgreSQL Docker settings
POSTGRES_VERSION=15-alpine

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=change-this-redis-password
REDIS_VERSION=7-alpine

# =============================================================================
# APPLICATION PORTS
# =============================================================================
# Frontend (React)
FRONTEND_PORT=3000

# Backend (FastAPI)
BACKEND_PORT=8000

# Database (PostgreSQL)
DB_PORT=5432

# Cache (Redis)
CACHE_PORT=6379

# Selenium Hub (for web scraping)
SELENIUM_PORT=4444

# =============================================================================
# VOLUME PATHS
# =============================================================================
# Database data persistence
DB_DATA_PATH=./data/postgres

# Redis data persistence  
REDIS_DATA_PATH=./data/redis

# Application logs
LOGS_PATH=./logs

# Scraped data storage
SCRAPED_DATA_PATH=./data/scraped

# =============================================================================
# SELENIUM CONFIGURATION
# =============================================================================
SELENIUM_VERSION=4.15.0
CHROME_VERSION=latest

# Selenium scaling (for production)
SELENIUM_NODE_MAX_SESSIONS=2
SELENIUM_NODE_MAX_INSTANCES=2

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Enable development features
DEV_MODE=true
DEBUG=true
HOT_RELOAD=true

# Development ports (alternative ports if main ones are in use)
DEV_FRONTEND_PORT=5173
DEV_BACKEND_PORT=8001

# =============================================================================
# SECURITY SETTINGS
# =============================================================================
# JWT Configuration
SECRET_KEY=your-super-secret-jwt-key-minimum-32-characters-change-in-production
ALGORITHM=HS256

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://127.0.0.1:3000,http://127.0.0.1:5173

# =============================================================================
# RESOURCE LIMITS
# =============================================================================
# Memory limits for containers (adjust based on your system)
FRONTEND_MEMORY=512m
BACKEND_MEMORY=1g
DATABASE_MEMORY=512m
REDIS_MEMORY=256m
SELENIUM_MEMORY=2g

# CPU limits
FRONTEND_CPUS=0.5
BACKEND_CPUS=1.0
DATABASE_CPUS=1.0
REDIS_CPUS=0.5
SELENIUM_CPUS=2.0

# =============================================================================
# BACKUP & MAINTENANCE
# =============================================================================
# Backup settings
BACKUP_SCHEDULE=0 2 * * *
BACKUP_RETENTION_DAYS=30

# Log rotation
LOG_MAX_SIZE=100m
LOG_MAX_FILES=10

# =============================================================================
# PRODUCTION OVERRIDES
# =============================================================================
# These should be set differently in production
# ENVIRONMENT=production
# DEBUG=false
# DEV_MODE=false
# HOT_RELOAD=false
# POSTGRES_PASSWORD=super-secure-production-password
# REDIS_PASSWORD=super-secure-redis-password
# SECRET_KEY=cryptographically-secure-production-key
</file>

<file path="frontend/.env.example">
# =============================================================================
# MIASMA FRONTEND ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit the actual .env file to version control

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
VITE_APP_NAME=Miasma
VITE_APP_VERSION=0.1.0
VITE_APP_DESCRIPTION=Personal Data Privacy Protection Service

# Environment
VITE_NODE_ENV=development

# =============================================================================
# API CONFIGURATION
# =============================================================================
# Backend API URL
VITE_API_BASE_URL=http://localhost:8000
VITE_API_VERSION=v1

# API Endpoints
VITE_API_URL=http://localhost:8000/api/v1

# WebSocket URL (for real-time updates)
VITE_WS_URL=ws://localhost:8000/ws

# =============================================================================
# AUTHENTICATION SETTINGS
# =============================================================================
# Token storage
VITE_TOKEN_STORAGE_KEY=miasma_access_token
VITE_REFRESH_TOKEN_KEY=miasma_refresh_token

# Session settings
VITE_SESSION_TIMEOUT_MINUTES=30
VITE_AUTO_REFRESH_TOKEN=true

# =============================================================================
# FEATURE FLAGS
# =============================================================================
# Enable/disable features during development
VITE_ENABLE_REGISTRATION=true
VITE_ENABLE_PASSWORD_RESET=true
VITE_ENABLE_ANALYTICS_DASHBOARD=true
VITE_ENABLE_CAMPAIGN_CREATION=true
VITE_ENABLE_DATA_EXPORT=true

# Debug features
VITE_ENABLE_DEBUG_MODE=true
VITE_SHOW_API_RESPONSES=false
VITE_MOCK_API_CALLS=false

# =============================================================================
# UI/UX SETTINGS
# =============================================================================
# Theme settings
VITE_DEFAULT_THEME=dark
VITE_ENABLE_THEME_SWITCHER=true

# Layout settings
VITE_SIDEBAR_COLLAPSED_DEFAULT=false
VITE_ENABLE_BREADCRUMBS=true

# Data refresh intervals (in seconds)
VITE_DASHBOARD_REFRESH_INTERVAL=30
VITE_CAMPAIGN_STATUS_REFRESH=10
VITE_LOOKUP_CACHE_TTL=300

# =============================================================================
# SCRAPING & LOOKUP SETTINGS
# =============================================================================
# Default lookup settings
VITE_MAX_LOOKUP_RESULTS=50
VITE_LOOKUP_TIMEOUT_SECONDS=30
VITE_ENABLE_PARALLEL_LOOKUPS=true

# Data source display settings
VITE_SHOW_SOURCE_RELIABILITY=true
VITE_SHOW_DATA_AGE=true
VITE_GROUP_SIMILAR_RESULTS=true

# =============================================================================
# CAMPAIGN SETTINGS
# =============================================================================
# Campaign creation limits
VITE_MAX_CAMPAIGNS_PER_USER=10
VITE_MAX_DATA_POINTS_PER_CAMPAIGN=50

# Campaign execution
VITE_SHOW_REAL_TIME_PROGRESS=true
VITE_ENABLE_CAMPAIGN_SCHEDULING=true
VITE_AUTO_VERIFY_SUBMISSIONS=true

# =============================================================================
# ANALYTICS & MONITORING
# =============================================================================
# Client-side analytics
VITE_ENABLE_USAGE_ANALYTICS=false
VITE_ANALYTICS_ENDPOINT=/api/v1/analytics

# Error tracking
VITE_SENTRY_DSN=your-frontend-sentry-dsn
VITE_ENABLE_ERROR_REPORTING=true

# Performance monitoring
VITE_ENABLE_PERFORMANCE_MONITORING=true
VITE_LOG_API_RESPONSE_TIMES=false

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Development server
VITE_DEV_SERVER_PORT=5173
VITE_DEV_SERVER_HOST=localhost

# Hot reload settings
VITE_HOT_RELOAD=true

# Development tools
VITE_SHOW_DEV_TOOLS=true
VITE_ENABLE_REACT_DEVTOOLS=true

# Mock data (for development without backend)
VITE_USE_MOCK_DATA=false
VITE_MOCK_DELAY_MS=500

# =============================================================================
# SECURITY SETTINGS
# =============================================================================
# CSP Settings
VITE_CSP_ENABLED=true

# HTTPS settings (for production)
VITE_FORCE_HTTPS=false

# =============================================================================
# EXTERNAL SERVICES
# =============================================================================
# Google Maps (if needed for address validation)
VITE_GOOGLE_MAPS_API_KEY=your-google-maps-api-key

# Stripe (if implementing paid features later)
VITE_STRIPE_PUBLISHABLE_KEY=your-stripe-publishable-key

# =============================================================================
# PRODUCTION OVERRIDES
# =============================================================================
# These will be overridden in production deployment
# VITE_API_BASE_URL=https://api.yourdomain.com
# VITE_WS_URL=wss://api.yourdomain.com/ws
# VITE_NODE_ENV=production
# VITE_ENABLE_DEBUG_MODE=false
# VITE_USE_MOCK_DATA=false
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Jack Dolan

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="readme.md">
# Miasma - Personal Data Poisoning Service

A defensive data poisoning platform that helps individuals protect their privacy by strategically introducing misleading information into commercial data broker networks.

## Project Goals

- **Privacy Protection**: Reduce the accuracy of personal data held by commercial data aggregators
- **Learning Platform**: Modern full-stack development with industry-standard tools and practices - using this as a learning side-project
- **Personal Use First**: Initially single-user (me), with potential for future expansion

## Tech Stack

### Frontend
- **React 18** - Modern component-based UI
- **Tailwind CSS** - Utility-first styling
- **Vite** - Fast build tool and dev server
- **React Query** - Server state management

### Backend
- **Python 3.11** - Core language
- **FastAPI** - High-performance async web framework
- **PostgreSQL** - Primary database for campaigns and results
- **Redis** - Caching and session management
- **SQLAlchemy** - ORM with async support

### Data Collection & Processing
- **Selenium** - Web automation and scraping
- **BeautifulSoup4** - HTML parsing, plus the website art is pretty
- **Requests** - HTTP client for APIs
- **Pandas** - Data manipulation and analysis

### Infrastructure & DevOps
- **Docker** - Containerization
- **Docker Compose** - Local development environment
- **AWS ECS** - Container orchestration
- **AWS RDS** - Managed PostgreSQL
- **AWS ElastiCache** - Managed Redis
- **GitHub Actions** - CI/CD pipeline
- **Snyk** - Security vulnerability scanning

## Architecture Overview

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   React SPA     │────│   FastAPI       │────│   PostgreSQL    │
│   (Frontend)    │    │   (Backend)     │    │   (Database)    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                              │
                       ┌──────┴──────┐
                       │    Redis    │
                       │  (Caching)  │
                       └─────────────┘
```

## Features (Planned)

### Phase 1: Core Infrastructure
- [ ] User authentication and profile management
- [ ] Data source discovery and monitoring
- [ ] Basic web scraping for personal data lookup

### Phase 2: Intelligence Gathering
- [ ] Automated scanning of major data broker sites
- [ ] Data source mapping and classification
- [ ] Personal data inventory and tracking

### Phase 3: Data Injection
- [ ] Fictitious data generation algorithms
- [ ] Automated form submission system
- [ ] Campaign management and tracking

### Phase 4: Verification & Analytics
- [ ] Success rate monitoring
- [ ] Data propagation tracking
- [ ] Effectiveness analytics dashboard

## Privacy & Legal Considerations

- **Scope Limitation**: Only targets commercial data brokers and voluntary submission sites
- **Government Exclusion**: Explicitly avoids interaction with official government sources
- **Personal Use**: Designed for individuals protecting their own data
- **Compliance**: Respects terms of service and applicable laws

## Quick Start

```bash
# Clone the repository
git clone https://github.com/jack-dolan/miasma.git
cd miasma

# Start development environment
docker-compose up -d

# Frontend development
cd frontend
npm install
npm run dev

# Backend development
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

## Development Workflow

1. **Feature Branch**: Create feature branches from `main`
2. **Development**: Use Docker Compose for local development
3. **Testing**: Automated testing with pytest and Jest
4. **Security**: Snyk scanning in CI pipeline
5. **Deployment**: Automated deployment to AWS via GitHub Actions

## Disclaimer

This tool is designed for legitimate privacy protection purposes. Users are responsible for ensuring their use complies with all applicable laws and terms of service.
</file>

</files>
